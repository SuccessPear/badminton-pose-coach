{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:26.193418Z",
     "start_time": "2025-09-27T19:54:24.247641Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from mlflow.recipes.steps.ingest import CustomDataset\n",
    "\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Legion\\anaconda3\\envs\\badminton-pose-coach\\Lib\\site-packages\\mlflow\\protos\\service_pb2.py:11: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
      "  from google.protobuf import service as _service\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Legion\\\\OneDrive\\\\Desktop\\\\Paris-Saclay\\\\Learning\\\\AI\\\\badminton-pose-coach'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:26.203288Z",
     "start_time": "2025-09-27T19:54:26.197944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    checkpoint_dir: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_device: str\n",
    "    params_lr: float\n",
    "    params_step_size: int\n",
    "    params_gamma: float\n",
    "    params_use_amp: bool\n"
   ],
   "id": "a080fa7ffea32471",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:28.630363Z",
     "start_time": "2025-09-27T19:54:26.208768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from badmintonPoseCoach.constants import *\n",
    "from badmintonPoseCoach.utils.common import read_yaml, create_directories"
   ],
   "id": "ce9b6666f5075483",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:28.639596Z",
     "start_time": "2025-09-27T19:54:28.634977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        prepare_base_model_config = self.config.prepare_base_model\n",
    "        training_config = self.config.training\n",
    "        params = self.params.training\n",
    "\n",
    "        create_directories([training_config.root_dir])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training_config.root_dir),\n",
    "            trained_model_path = Path(training_config.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model_config.updated_base_model_path),\n",
    "            training_data = Path(training_config.training_data),\n",
    "            checkpoint_dir = Path(training_config.checkpoint_dir),\n",
    "            params_epochs = params.epochs,\n",
    "            params_batch_size = params.batch_size,\n",
    "            params_device = params.device,\n",
    "            params_step_size = params.step_size,\n",
    "            params_lr = params.lr,\n",
    "            params_gamma = params.gamma,\n",
    "            params_use_amp = params.use_amp,\n",
    "        )\n",
    "        return training_config"
   ],
   "id": "4f069c63b2241538",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:28.646508Z",
     "start_time": "2025-09-27T19:54:28.644089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ],
   "id": "1b48c5e52b99d1fe",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:28.661638Z",
     "start_time": "2025-09-27T19:54:28.650841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BadmintonPoseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class that load json file and output a dataframe of keypoints\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config: TrainingConfig,\n",
    "                 seed: int = 42,\n",
    "                 split: str = 'train',\n",
    "                 split_ratio: tuple[float, float, float] = (0.8, 0.1, 0.1),\n",
    "                 frame_format: str = 'auto',\n",
    "                 num_joints: int = 17,):\n",
    "        self.training_data = Path(config.training_data)\n",
    "        self.frame_format = frame_format\n",
    "        self.num_joints = num_joints\n",
    "\n",
    "        class_dirs = sorted([d for d in self.training_data.iterdir() if d.is_dir()])\n",
    "        self.class_names = [d.name for d in class_dirs]\n",
    "\n",
    "        # list all files in data folder\n",
    "        self.file_list = []\n",
    "        for ci, d in enumerate(class_dirs):\n",
    "            for p in sorted(d.rglob(\"*.json\")):\n",
    "                self.file_list.append((p, ci))\n",
    "\n",
    "        # Train/val/test split\n",
    "        g = torch.Generator().manual_seed(seed)\n",
    "        per_class_idx = [[] for _ in self.class_names]\n",
    "        for idx, (_p, ci) in enumerate(self.file_list):\n",
    "            per_class_idx[ci].append(idx)\n",
    "        for lst in per_class_idx:\n",
    "            perm = torch.randperm(len(lst), generator=g).tolist()\n",
    "            lst = [lst[i] for i in perm]\n",
    "\n",
    "        def take_splits(idxs: list[int]) -> tuple[list[int], list[int], list[int]]:\n",
    "            n = len(idxs)\n",
    "            n_train = int(n * split_ratio[0])\n",
    "            n_val = int(n * split_ratio[1])\n",
    "            return idxs[:n_train], idxs[n_train:n_train+n_val], idxs[n_train+n_val:]\n",
    "\n",
    "        split_map = {\"train\": 0, \"val\": 1, \"valid\": 1, \"validation\": 1, \"test\": 2}\n",
    "        which = split_map[split]\n",
    "\n",
    "        selected: list[int] = []\n",
    "        for lst in per_class_idx:\n",
    "            tr, va, te = take_splits(lst)\n",
    "            selected.extend([tr, va, te][which])\n",
    "        selected = sorted(selected)\n",
    "\n",
    "        self.files: list[Path] = [self.file_list[i][0] for i in selected]\n",
    "        self.labels: list[int] = [self.file_list[i][1] for i in selected]\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.FloatTensor, int]:\n",
    "        path = self.files[index]\n",
    "        label = self.labels[index]\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            obj = json.load(f)\n",
    "\n",
    "        seq = obj.get(\"seq\")\n",
    "        if seq is None:\n",
    "            raise ValueError(f\"Missing 'seq' in {path}\")\n",
    "\n",
    "        pose = self._to_tensor_TxKx3(seq)\n",
    "\n",
    "        return self.normalize_pose(pose, 720, 1280), label\n",
    "\n",
    "    def _to_tensor_TxKx3(self, seq: any) -> torch.tensor:\n",
    "        if self.frame_format in (\"auto\", \"Kx3\") and isinstance(seq, list) and len(seq) > 0 and isinstance(seq[0], list):\n",
    "            sample = seq[0]\n",
    "            if len(sample) > 0 and isinstance(sample[0], list):\n",
    "                return torch.tensor(seq, dtype=torch.float32)\n",
    "            else:\n",
    "                if self.frame_format == \"flat\" and self.num_joints is not None:\n",
    "                    K = int(self.num_joints)\n",
    "                else:\n",
    "                    flen = len(sample)\n",
    "                    if flen % 3 != 0:\n",
    "                        raise ValueError(\"Cannot infer num_keypoints\")\n",
    "                    K = flen // 3\n",
    "                frames_Kx3 = []\n",
    "                for fr in seq:\n",
    "                    triplets = [fr[i:i+3] for i in range(0, len(fr), 3)]\n",
    "                    frames_Kx3.append(triplets)\n",
    "                return torch.tensor(frames_Kx3, dtype=torch.float32)\n",
    "\n",
    "        if self.frame_format in (\"auto\", \"flat\") and isinstance(seq, list) and seq and isinstance(seq[0], (int,float)):\n",
    "            if self.num_joints is None:\n",
    "                raise ValueError(\"Need num_keypoints for flat seq\")\n",
    "            K = int(self.num_joints)\n",
    "            T = len(seq) // (K*3)\n",
    "            return torch.tensor(seq, dtype=torch.float32).view(T, K, 3)\n",
    "\n",
    "        raise ValueError(\"Unsupported 'seq' structure\")\n",
    "    @staticmethod\n",
    "    def normalize_pose(pose, W, H, method=\"skeleton\"):\n",
    "        # pose: (T,K,3)\n",
    "        if method == \"image\":\n",
    "            pose[...,0] /= W\n",
    "            pose[...,1] /= H\n",
    "        elif method == \"skeleton\":\n",
    "            # pelvis = joint 11,12 in average\n",
    "            pelvis = pose[:,[11,12],:2].mean(1, keepdims=True)\n",
    "            pose[...,:2] -= pelvis\n",
    "            # scale with the shoulder\n",
    "            shoulder = pose[:,[5,6],:2].mean(1, keepdims=True)\n",
    "            scale = (pose[:,5,:2]-pose[:,6,:2]).norm(dim=-1, keepdim=True).clamp(min=1e-6)\n",
    "            pose[...,:2] /= scale[:,None,:]\n",
    "        return pose"
   ],
   "id": "b1358d5fd4e2a9bf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:28.671343Z",
     "start_time": "2025-09-27T19:54:28.666317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "def pack_collate(batch: list[tuple[torch.tensor, int]]) -> dict[str, any]:\n",
    "    \"\"\"\n",
    "    Collate function sử dụng torch.nn.utils.rnn.pack_padded_sequence.\n",
    "    - pose: (T,K,3) với T có thể khác nhau\n",
    "    - Trả về PackedSequence để dùng cho RNN.\n",
    "\n",
    "    Returns:\n",
    "      packed: PackedSequence chứa (T, K*3)\n",
    "      lengths: chiều dài thực tế từng sample\n",
    "      labels: (B,)\n",
    "    \"\"\"\n",
    "    poses, labels = zip(*batch)\n",
    "    lengths = torch.tensor([p.shape[0] for p in poses], dtype=torch.long)\n",
    "    K = poses[0].shape[1]\n",
    "\n",
    "    # Flatten (T,K,3) -> (T, K*3)\n",
    "    flat_poses = [p.reshape(p.shape[0], K*3) for p in poses]\n",
    "    padded = torch.nn.utils.rnn.pad_sequence(flat_poses, batch_first=True)\n",
    "\n",
    "    packed = pack_padded_sequence(padded, lengths, batch_first=True, enforce_sorted=False)\n",
    "    labels_t = torch.tensor(labels, dtype=torch.long)\n",
    "    return {\"packed\": packed, \"lengths\": lengths, \"labels\": labels_t}"
   ],
   "id": "5da00f59611977fd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:54:28.687400Z",
     "start_time": "2025-09-27T19:54:28.675666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config: TrainingConfig,\n",
    "                 train_loader: torch.utils.data.DataLoader,\n",
    "                 val_loader: torch.utils.data.DataLoader,\n",
    "                 test_loader: torch.utils.data.DataLoader,):\n",
    "        self.config = config\n",
    "        self.device = config.params_device\n",
    "\n",
    "        self.model = torch.load(self.config.updated_base_model_path, weights_only=False).to(self.device)\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.params_lr)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=config.params_step_size, gamma=config.params_gamma)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "         # AMP\n",
    "        self.scaler = torch.amp.GradScaler(\"cuda\", enabled=config.params_use_amp and self.device == \"cuda\")\n",
    "        # Checkpoint dir\n",
    "        Path(config.checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        torch.save(self.model, self.config.trained_model_path)\n",
    "\n",
    "    def _step_batch(self, batch, train: bool = True) -> tuple[float, float]:\n",
    "        packed = batch[\"packed\"]\n",
    "        labels = batch[\"labels\"].to(self.device)\n",
    "        packed = packed.to(self.device)\n",
    "\n",
    "        with torch.amp.autocast(\"cuda\", enabled=self.scaler.is_enabled()):\n",
    "\n",
    "            logits = self.model(packed)\n",
    "\n",
    "            loss = self.criterion(logits, labels)\n",
    "        if train:\n",
    "            self.optimizer.zero_grad(set_to_none=True)\n",
    "            self.scaler.scale(loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        with torch.no_grad():\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            acc = (preds == labels).float().mean().item()\n",
    "        return loss.item(), acc\n",
    "\n",
    "    def train_one_epoch(self, epoch: int) -> tuple[float, float]:\n",
    "        self.model.train()\n",
    "        total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "        for batch in tqdm(self.train_loader):\n",
    "            loss, acc = self._step_batch(batch, train=True)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            n += 1\n",
    "        avg_loss = total_loss / max(n, 1)\n",
    "        avg_acc = total_acc / max(n, 1)\n",
    "        return avg_loss, avg_acc\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, split: str = \"val\") -> tuple[float, float]:\n",
    "        self.model.eval()\n",
    "        loader = {\"val\": self.val_loader, \"test\": self.test_loader}[split]\n",
    "        total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "        for batch in tqdm(loader):\n",
    "            loss, acc = self._step_batch(batch, train=False)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "            n += 1\n",
    "        return total_loss / max(n, 1), total_acc / max(n, 1)\n",
    "\n",
    "    def fit(self):\n",
    "        best_val_acc = 0.0\n",
    "        for epoch in range(1, self.config.params_epochs + 1):\n",
    "            train_loss, train_acc = self.train_one_epoch(epoch)\n",
    "            val_loss, val_acc = self.evaluate(\"val\")\n",
    "            self.scheduler.step()\n",
    "\n",
    "            print(f\"Epoch {epoch:03d}: train loss {train_loss:.4f}, acc {train_acc:.4f} | \"\n",
    "                  f\"val loss {val_loss:.4f}, acc {val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                ckpt_path = Path(self.config.checkpoint_dir) / f\"best.pkl\"\n",
    "                torch.save({\n",
    "                    \"model_state\": self.model.state_dict(),\n",
    "                    \"cfg\": self.config.__dict__,\n",
    "                    \"val_acc\": val_acc,\n",
    "                }, ckpt_path)\n",
    "                print(f\"Saved checkpoint to {ckpt_path}\")\n",
    "\n",
    "        print(f\"Best val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self):\n",
    "        ckpt_path = Path(self.config.checkpoint_dir) / \"best.pkl\"\n",
    "        if ckpt_path.exists():\n",
    "            state = torch.load(ckpt_path, map_location=self.device, weights_only=False)\n",
    "            self.model.load_state_dict(state[\"model_state\"])\n",
    "            print(f\"Loaded checkpoint from {ckpt_path}\")\n",
    "        test_loss, test_acc = self.evaluate(\"test\")\n",
    "        print(f\"Test: loss {test_loss:.4f}, acc {test_acc:.4f}\")\n"
   ],
   "id": "9cdfed2333c9878a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:56:19.596323Z",
     "start_time": "2025-09-27T19:54:28.699138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = ConfigurationManager()\n",
    "train_config = config.get_training_config()\n",
    "train_data = BadmintonPoseDataset(train_config, split='train')\n",
    "val_data = BadmintonPoseDataset(train_config, split='val')\n",
    "test_data = BadmintonPoseDataset(train_config, split='test')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=train_config.params_batch_size, collate_fn=pack_collate, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=train_config.params_batch_size, collate_fn=pack_collate, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=train_config.params_batch_size, collate_fn=pack_collate)\n",
    "\n",
    "trainer = Trainer(train_config, train_loader, val_loader, test_loader)\n",
    "trainer.fit()\n",
    "trainer.test()\n"
   ],
   "id": "72ad89fc967e9f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-27 21:54:28,703: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-09-27 21:54:28,706: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-09-27 21:54:28,707: INFO: common: created directory at: artifacts]\n",
      "[2025-09-27 21:54:28,709: INFO: common: created directory at: artifacts/training]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: train loss 1.8337, acc 0.4521 | val loss 1.8453, acc 0.4732\n",
      "Saved checkpoint to artifacts\\training\\checkpoints\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:12<00:00, 31.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002: train loss 1.3952, acc 0.5833 | val loss 1.7189, acc 0.5077\n",
      "Saved checkpoint to artifacts\\training\\checkpoints\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:11<00:00, 33.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003: train loss 1.2543, acc 0.6210 | val loss 1.6444, acc 0.5204\n",
      "Saved checkpoint to artifacts\\training\\checkpoints\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 41.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004: train loss 1.1735, acc 0.6380 | val loss 1.5576, acc 0.5255\n",
      "Saved checkpoint to artifacts\\training\\checkpoints\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 41.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005: train loss 1.1077, acc 0.6603 | val loss 1.5101, acc 0.5727\n",
      "Saved checkpoint to artifacts\\training\\checkpoints\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 41.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006: train loss 1.0346, acc 0.6746 | val loss 1.5714, acc 0.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 42.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007: train loss 0.9779, acc 0.6910 | val loss 1.5739, acc 0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008: train loss 0.9141, acc 0.7109 | val loss 1.4350, acc 0.5995\n",
      "Saved checkpoint to artifacts\\training\\checkpoints\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 41.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009: train loss 0.8802, acc 0.7167 | val loss 1.4250, acc 0.5778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 389/389 [00:09<00:00, 41.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010: train loss 0.8062, acc 0.7416 | val loss 1.7362, acc 0.5383\n",
      "Best val acc: 0.5995\n",
      "Loaded checkpoint from artifacts\\training\\checkpoints\\best.pt\n",
      "Test: loss 1.3006, acc 0.6221\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:56:19.624625Z",
     "start_time": "2025-09-27T19:56:19.620911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 2 frame, 4 keypoints, 3 giá trị (x,y,score)\n",
    "pose = np.array([\n",
    "    [[10, 20, 0.9], [30, 40, 0.8], [50, 60, 0.7], [70, 80, 0.6]],\n",
    "    [[15, 25, 0.95], [35, 45, 0.85], [55, 65, 0.75], [75, 85, 0.65]]\n",
    "])  # shape (2,4,3)\n",
    "\n",
    "print(pose[...,0])  # lấy toàn bộ x -> shape (2,4)\n",
    "# [[10 30 50 70]\n",
    "#  [15 35 55 75]]\n",
    "\n",
    "print(pose[...,1])  # lấy toàn bộ y -> shape (2,4)\n",
    "# [[20 40 60 80]\n",
    "#  [25 45 65 85]]"
   ],
   "id": "c57a0585c7b17f67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[         10          30          50          70]\n",
      " [         15          35          55          75]]\n",
      "[[         20          40          60          80]\n",
      " [         25          45          65          85]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T19:56:19.670350Z",
     "start_time": "2025-09-27T19:56:19.656229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_pose(pose, W, H, method=\"skeleton\"):\n",
    "    # pose: (T,K,3)\n",
    "    if method == \"image\":\n",
    "        pose[...,0] /= W\n",
    "        pose[...,1] /= H\n",
    "    elif method == \"skeleton\":\n",
    "        # pelvis = joint 11,12 in average\n",
    "        pelvis = pose[:,[11,12],:2].mean(1, keepdims=True)\n",
    "        pose[...,:2] -= pelvis\n",
    "        # scale with the shoulder\n",
    "        shoulder = pose[:,[5,6],:2].mean(1, keepdims=True)\n",
    "        scale = (pose[:,5,:2]-pose[:,6,:2]).norm(dim=-1, keepdim=True).clamp(min=1e-6)\n",
    "        pose[...,:2] /= scale[:,None,:]\n",
    "    return pose\n",
    "\n",
    "#train_data[0][0]\n",
    "normalize_pose(train_data[0][0], 720,1280, \"skeleton\")"
   ],
   "id": "a7b6d3f500f2fe0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.9153e-01, -1.6061e+00,  1.2644e-01],\n",
       "         [-3.5748e-01, -1.6992e+00,  1.4010e-01],\n",
       "         [-3.1302e-01, -1.7031e+00,  3.0042e-02],\n",
       "         [-2.8901e-01, -1.6639e+00,  8.8703e-01],\n",
       "         [ 1.0857e-01, -1.6435e+00,  3.2072e-01],\n",
       "         [-5.6635e-01, -1.2585e+00,  9.9525e-01],\n",
       "         [ 4.3139e-01, -1.1913e+00,  9.8801e-01],\n",
       "         [-1.0255e+00, -1.0691e+00,  9.7379e-01],\n",
       "         [ 7.3381e-01, -9.3401e-01,  8.5509e-01],\n",
       "         [-1.1087e+00, -1.1081e+00,  8.9493e-01],\n",
       "         [ 7.4719e-01, -1.0355e+00,  6.6659e-01],\n",
       "         [-3.2455e-01, -2.1698e-02,  9.9826e-01],\n",
       "         [ 3.2455e-01,  2.1698e-02,  9.9710e-01],\n",
       "         [-5.1888e-01,  7.7028e-01,  9.9477e-01],\n",
       "         [ 2.7007e-01,  8.2048e-01,  9.8932e-01],\n",
       "         [-4.7282e-01,  1.6781e+00,  9.8510e-01],\n",
       "         [ 2.9500e-01,  1.7270e+00,  9.7517e-01]],\n",
       "\n",
       "        [[-3.4170e-01, -1.6471e+00,  1.1605e-01],\n",
       "         [-3.0739e-01, -1.7378e+00,  1.1529e-01],\n",
       "         [-2.6835e-01, -1.7437e+00,  3.0186e-02],\n",
       "         [-2.5567e-01, -1.7072e+00,  8.6945e-01],\n",
       "         [ 1.2474e-01, -1.6888e+00,  3.6126e-01],\n",
       "         [-5.2834e-01, -1.2883e+00,  9.9498e-01],\n",
       "         [ 4.7023e-01, -1.2347e+00,  9.9021e-01],\n",
       "         [-1.0360e+00, -1.0775e+00,  9.7104e-01],\n",
       "         [ 8.5976e-01, -9.8563e-01,  8.9363e-01],\n",
       "         [-1.2278e+00, -1.0985e+00,  8.8651e-01],\n",
       "         [ 8.7551e-01, -1.0470e+00,  7.1750e-01],\n",
       "         [-3.1566e-01, -1.6147e-02,  9.9829e-01],\n",
       "         [ 3.1566e-01,  1.6147e-02,  9.9752e-01],\n",
       "         [-4.7817e-01,  8.2788e-01,  9.9404e-01],\n",
       "         [ 2.5024e-01,  8.6472e-01,  9.8961e-01],\n",
       "         [-4.3168e-01,  1.7466e+00,  9.8187e-01],\n",
       "         [ 2.2288e-01,  1.7799e+00,  9.7311e-01]],\n",
       "\n",
       "        [[-3.1142e-01, -1.5757e+00,  7.9490e-02],\n",
       "         [-2.7912e-01, -1.6600e+00,  7.3939e-02],\n",
       "         [-2.3739e-01, -1.6639e+00,  2.2811e-02],\n",
       "         [-2.5380e-01, -1.6450e+00,  8.2297e-01],\n",
       "         [ 1.3992e-01, -1.6194e+00,  3.6097e-01],\n",
       "         [-5.4328e-01, -1.2587e+00,  9.9329e-01],\n",
       "         [ 4.5442e-01, -1.1910e+00,  9.8887e-01],\n",
       "         [-1.0653e+00, -1.0225e+00,  9.6614e-01],\n",
       "         [ 9.3210e-01, -9.1226e-01,  9.0601e-01],\n",
       "         [-1.2411e+00, -9.4885e-01,  8.7099e-01],\n",
       "         [ 1.0368e+00, -8.9422e-01,  7.3050e-01],\n",
       "         [-3.0090e-01, -2.0496e-02,  9.9809e-01],\n",
       "         [ 3.0090e-01,  2.0496e-02,  9.9750e-01],\n",
       "         [-3.9230e-01,  8.3095e-01,  9.9276e-01],\n",
       "         [ 1.4879e-01,  8.7272e-01,  9.8865e-01],\n",
       "         [-2.3378e-01,  1.6810e+00,  9.7698e-01],\n",
       "         [ 1.0733e-01,  1.7224e+00,  9.6839e-01]],\n",
       "\n",
       "        [[-3.1326e-01, -1.5723e+00,  6.9250e-02],\n",
       "         [-2.7751e-01, -1.6560e+00,  6.7053e-02],\n",
       "         [-2.3353e-01, -1.6583e+00,  1.9041e-02],\n",
       "         [-2.4863e-01, -1.6467e+00,  8.2071e-01],\n",
       "         [ 1.5231e-01, -1.6156e+00,  3.2428e-01],\n",
       "         [-5.3687e-01, -1.2626e+00,  9.9296e-01],\n",
       "         [ 4.6003e-01, -1.1839e+00,  9.8740e-01],\n",
       "         [-1.0589e+00, -9.9391e-01,  9.6713e-01],\n",
       "         [ 9.7537e-01, -8.7068e-01,  8.9686e-01],\n",
       "         [-1.2425e+00, -8.7619e-01,  8.7354e-01],\n",
       "         [ 1.1028e+00, -8.1686e-01,  7.1419e-01],\n",
       "         [-2.9364e-01, -2.2273e-02,  9.9816e-01],\n",
       "         [ 2.9364e-01,  2.2273e-02,  9.9749e-01],\n",
       "         [-3.5551e-01,  8.1618e-01,  9.9339e-01],\n",
       "         [ 8.7771e-02,  8.5996e-01,  9.8912e-01],\n",
       "         [-1.1495e-01,  1.6501e+00,  9.7921e-01],\n",
       "         [ 6.6002e-02,  1.6957e+00,  9.7041e-01]],\n",
       "\n",
       "        [[-2.2398e-01, -1.4695e+00,  1.4014e-01],\n",
       "         [-1.9431e-01, -1.5523e+00,  1.0601e-01],\n",
       "         [-1.2344e-01, -1.5508e+00,  4.0725e-02],\n",
       "         [-1.5966e-01, -1.5667e+00,  7.8057e-01],\n",
       "         [ 2.6272e-01, -1.5298e+00,  3.9968e-01],\n",
       "         [-4.6358e-01, -1.1957e+00,  9.9130e-01],\n",
       "         [ 5.3315e-01, -1.1148e+00,  9.8679e-01],\n",
       "         [-9.1636e-01, -8.6237e-01,  9.5737e-01],\n",
       "         [ 1.0349e+00, -7.2275e-01,  8.9825e-01],\n",
       "         [-8.9340e-01, -7.2745e-01,  8.5772e-01],\n",
       "         [ 1.2698e+00, -6.4502e-01,  7.2717e-01],\n",
       "         [-2.9779e-01, -2.1275e-02,  9.9647e-01],\n",
       "         [ 2.9779e-01,  2.1275e-02,  9.9543e-01],\n",
       "         [-3.1206e-01,  8.5167e-01,  9.8647e-01],\n",
       "         [ 1.5099e-01,  8.9388e-01,  9.7987e-01],\n",
       "         [-5.0928e-02,  1.6020e+00,  9.5530e-01],\n",
       "         [ 1.9495e-01,  1.6488e+00,  9.4167e-01]],\n",
       "\n",
       "        [[-2.5707e-01, -1.4795e+00,  1.5494e-01],\n",
       "         [-2.3576e-01, -1.5610e+00,  1.1268e-01],\n",
       "         [-1.6599e-01, -1.5644e+00,  4.8933e-02],\n",
       "         [-2.2484e-01, -1.5555e+00,  7.4339e-01],\n",
       "         [ 2.1941e-01, -1.5347e+00,  4.0983e-01],\n",
       "         [-5.1158e-01, -1.1537e+00,  9.8921e-01],\n",
       "         [ 4.8732e-01, -1.1068e+00,  9.8526e-01],\n",
       "         [-9.5988e-01, -7.4783e-01,  9.4836e-01],\n",
       "         [ 9.0977e-01, -6.5072e-01,  8.9716e-01],\n",
       "         [-9.2347e-01, -6.1246e-01,  8.3975e-01],\n",
       "         [ 1.0887e+00, -5.5157e-01,  7.3065e-01],\n",
       "         [-2.9902e-01, -1.4807e-02,  9.9501e-01],\n",
       "         [ 2.9902e-01,  1.4807e-02,  9.9390e-01],\n",
       "         [-3.1845e-01,  8.6173e-01,  9.8039e-01],\n",
       "         [ 1.1124e-01,  8.9494e-01,  9.7279e-01],\n",
       "         [-7.8988e-02,  1.6226e+00,  9.3558e-01],\n",
       "         [ 1.0537e-01,  1.6499e+00,  9.2038e-01]],\n",
       "\n",
       "        [[-2.4172e-01, -1.5792e+00,  7.8340e-02],\n",
       "         [-2.2833e-01, -1.6612e+00,  6.4939e-02],\n",
       "         [-1.8361e-01, -1.6719e+00,  2.7389e-02],\n",
       "         [-3.1480e-01, -1.6425e+00,  7.6912e-01],\n",
       "         [ 1.5701e-01, -1.6378e+00,  4.2941e-01],\n",
       "         [-5.7541e-01, -1.2025e+00,  9.9249e-01],\n",
       "         [ 4.2389e-01, -1.1653e+00,  9.8867e-01],\n",
       "         [-9.9708e-01, -6.7787e-01,  9.5917e-01],\n",
       "         [ 9.0465e-01, -5.9324e-01,  9.0448e-01],\n",
       "         [-1.0837e+00, -4.0560e-01,  8.4065e-01],\n",
       "         [ 1.0167e+00, -3.6715e-01,  7.0890e-01],\n",
       "         [-3.0684e-01, -1.4473e-02,  9.9748e-01],\n",
       "         [ 3.0684e-01,  1.4473e-02,  9.9680e-01],\n",
       "         [-3.2986e-01,  8.3721e-01,  9.8972e-01],\n",
       "         [ 9.9826e-02,  8.6726e-01,  9.8482e-01],\n",
       "         [-1.5429e-01,  1.6456e+00,  9.6764e-01],\n",
       "         [ 4.0918e-02,  1.6648e+00,  9.5752e-01]],\n",
       "\n",
       "        [[-2.9980e-01, -1.6602e+00,  1.0632e-01],\n",
       "         [-2.8785e-01, -1.7445e+00,  7.5501e-02],\n",
       "         [-2.4516e-01, -1.7627e+00,  4.1303e-02],\n",
       "         [-3.7982e-01, -1.7157e+00,  7.4517e-01],\n",
       "         [ 8.8129e-02, -1.7320e+00,  5.1022e-01],\n",
       "         [-6.2161e-01, -1.2288e+00,  9.9283e-01],\n",
       "         [ 3.7839e-01, -1.2272e+00,  9.9205e-01],\n",
       "         [-1.0209e+00, -6.0446e-01,  9.5220e-01],\n",
       "         [ 8.8373e-01, -5.7745e-01,  9.3124e-01],\n",
       "         [-1.1173e+00, -2.3546e-01,  8.2611e-01],\n",
       "         [ 9.7912e-01, -2.2848e-01,  7.6459e-01],\n",
       "         [-3.1647e-01, -8.2819e-03,  9.9753e-01],\n",
       "         [ 3.1647e-01,  8.2819e-03,  9.9733e-01],\n",
       "         [-2.9409e-01,  9.0701e-01,  9.8962e-01],\n",
       "         [ 2.3751e-01,  9.2316e-01,  9.8731e-01],\n",
       "         [-1.6835e-01,  1.7637e+00,  9.6837e-01],\n",
       "         [ 2.0396e-01,  1.7575e+00,  9.6376e-01]],\n",
       "\n",
       "        [[-3.9864e-01, -1.7930e+00,  1.6123e-01],\n",
       "         [-3.8446e-01, -1.8820e+00,  1.0737e-01],\n",
       "         [-3.4613e-01, -1.9063e+00,  6.2593e-02],\n",
       "         [-4.8317e-01, -1.8408e+00,  7.7419e-01],\n",
       "         [-1.1089e-02, -1.8749e+00,  5.6899e-01],\n",
       "         [-6.8283e-01, -1.2952e+00,  9.9505e-01],\n",
       "         [ 3.1673e-01, -1.3251e+00,  9.9501e-01],\n",
       "         [-1.0210e+00, -5.6086e-01,  9.5787e-01],\n",
       "         [ 8.9113e-01, -5.9051e-01,  9.4555e-01],\n",
       "         [-1.1539e+00,  2.3589e-02,  8.4665e-01],\n",
       "         [ 9.6515e-01, -1.3478e-02,  8.0355e-01],\n",
       "         [-3.2761e-01, -1.0669e-03,  9.9837e-01],\n",
       "         [ 3.2761e-01,  1.0669e-03,  9.9829e-01],\n",
       "         [-3.3914e-01,  1.0056e+00,  9.9389e-01],\n",
       "         [ 3.3862e-01,  1.0025e+00,  9.9279e-01],\n",
       "         [-1.9367e-01,  1.9346e+00,  9.8274e-01],\n",
       "         [ 4.4789e-01,  1.8968e+00,  9.8066e-01]],\n",
       "\n",
       "        [[-5.2667e-01, -1.9252e+00,  1.4954e-01],\n",
       "         [-4.9586e-01, -2.0241e+00,  1.3717e-01],\n",
       "         [-4.4158e-01, -2.0499e+00,  3.8962e-02],\n",
       "         [-4.8960e-01, -1.9629e+00,  8.5682e-01],\n",
       "         [-1.5718e-02, -1.9989e+00,  3.6379e-01],\n",
       "         [-6.3730e-01, -1.3678e+00,  9.9502e-01],\n",
       "         [ 3.6181e-01, -1.4099e+00,  9.9007e-01],\n",
       "         [-9.5545e-01, -6.2655e-01,  9.7124e-01],\n",
       "         [ 7.9965e-01, -6.8074e-01,  8.9028e-01],\n",
       "         [-1.1765e+00, -8.6715e-02,  8.8925e-01],\n",
       "         [ 7.5007e-01, -1.1694e-01,  7.2139e-01],\n",
       "         [-3.4142e-01,  7.5982e-03,  9.9846e-01],\n",
       "         [ 3.4142e-01, -7.5982e-03,  9.9764e-01],\n",
       "         [-5.2230e-01,  1.0563e+00,  9.9590e-01],\n",
       "         [ 3.8052e-01,  1.0438e+00,  9.9259e-01],\n",
       "         [-4.3985e-01,  2.0604e+00,  9.8939e-01],\n",
       "         [ 6.2179e-01,  2.0038e+00,  9.8383e-01]],\n",
       "\n",
       "        [[-6.9605e-01, -1.7801e+00,  1.1202e-01],\n",
       "         [-6.7208e-01, -1.8707e+00,  8.6338e-02],\n",
       "         [-5.9728e-01, -1.9071e+00,  2.9227e-02],\n",
       "         [-6.2697e-01, -1.8262e+00,  7.9933e-01],\n",
       "         [-1.4926e-01, -1.8948e+00,  3.6817e-01],\n",
       "         [-7.3985e-01, -1.2839e+00,  9.9309e-01],\n",
       "         [ 2.5526e-01, -1.3826e+00,  9.9113e-01],\n",
       "         [-1.0560e+00, -5.3908e-01,  9.5899e-01],\n",
       "         [ 7.3606e-01, -6.8431e-01,  9.2399e-01],\n",
       "         [-1.2314e+00, -5.4064e-03,  8.5697e-01],\n",
       "         [ 7.6948e-01, -1.0360e-01,  7.7415e-01],\n",
       "         [-3.3831e-01,  1.8753e-02,  9.9828e-01],\n",
       "         [ 3.3831e-01, -1.8753e-02,  9.9797e-01],\n",
       "         [-5.9376e-01,  9.9749e-01,  9.9519e-01],\n",
       "         [ 3.4439e-01,  9.5971e-01,  9.9341e-01],\n",
       "         [-5.6469e-01,  2.0255e+00,  9.8782e-01],\n",
       "         [ 5.5971e-01,  1.9338e+00,  9.8489e-01]],\n",
       "\n",
       "        [[-5.4978e-01, -1.7949e+00,  1.2990e-01],\n",
       "         [-5.3416e-01, -1.8839e+00,  8.2168e-02],\n",
       "         [-4.6927e-01, -1.9177e+00,  4.5081e-02],\n",
       "         [-5.4848e-01, -1.8339e+00,  7.2833e-01],\n",
       "         [-9.3048e-02, -1.8970e+00,  4.8900e-01],\n",
       "         [-7.0415e-01, -1.2848e+00,  9.9246e-01],\n",
       "         [ 2.9117e-01, -1.3815e+00,  9.9308e-01],\n",
       "         [-1.0343e+00, -5.4231e-01,  9.5146e-01],\n",
       "         [ 7.8068e-01, -6.8626e-01,  9.4839e-01],\n",
       "         [-1.1749e+00,  1.6988e-02,  8.4414e-01],\n",
       "         [ 8.3430e-01, -7.3093e-02,  8.2691e-01],\n",
       "         [-3.3711e-01,  1.7513e-02,  9.9819e-01],\n",
       "         [ 3.3711e-01, -1.7513e-02,  9.9819e-01],\n",
       "         [-5.0431e-01,  1.0192e+00,  9.9443e-01],\n",
       "         [ 4.0945e-01,  9.8506e-01,  9.9378e-01],\n",
       "         [-5.0182e-01,  2.0619e+00,  9.8550e-01],\n",
       "         [ 5.7586e-01,  1.9789e+00,  9.8448e-01]],\n",
       "\n",
       "        [[-5.9641e-01, -1.7922e+00,  1.1313e-01],\n",
       "         [-5.6951e-01, -1.8875e+00,  8.2846e-02],\n",
       "         [-5.2092e-01, -1.9172e+00,  3.5570e-02],\n",
       "         [-5.8199e-01, -1.8299e+00,  7.7644e-01],\n",
       "         [-9.1008e-02, -1.8862e+00,  4.2936e-01],\n",
       "         [-7.2423e-01, -1.2985e+00,  9.9409e-01],\n",
       "         [ 2.7332e-01, -1.3683e+00,  9.9319e-01],\n",
       "         [-1.0015e+00, -5.6865e-01,  9.5767e-01],\n",
       "         [ 7.6391e-01, -6.7597e-01,  9.3559e-01],\n",
       "         [-1.1057e+00,  1.6878e-02,  8.4590e-01],\n",
       "         [ 8.0767e-01, -8.6912e-02,  7.8617e-01],\n",
       "         [-3.3881e-01,  1.1290e-02,  9.9845e-01],\n",
       "         [ 3.3881e-01, -1.1290e-02,  9.9831e-01],\n",
       "         [-5.0259e-01,  1.0084e+00,  9.9477e-01],\n",
       "         [ 3.7463e-01,  9.8491e-01,  9.9351e-01],\n",
       "         [-3.9862e-01,  1.9860e+00,  9.8584e-01],\n",
       "         [ 5.9713e-01,  1.9170e+00,  9.8347e-01]],\n",
       "\n",
       "        [[-5.6069e-01, -1.8904e+00,  1.9535e-01],\n",
       "         [-5.4089e-01, -1.9845e+00,  1.3188e-01],\n",
       "         [-4.9496e-01, -2.0164e+00,  7.1750e-02],\n",
       "         [-6.0728e-01, -1.9448e+00,  7.5455e-01],\n",
       "         [-1.5142e-01, -2.0041e+00,  4.9927e-01],\n",
       "         [-7.4755e-01, -1.3617e+00,  9.9177e-01],\n",
       "         [ 2.4795e-01, -1.4564e+00,  9.9093e-01],\n",
       "         [-1.0845e+00, -5.8340e-01,  9.5182e-01],\n",
       "         [ 8.2020e-01, -7.2736e-01,  9.3259e-01],\n",
       "         [-1.2771e+00,  1.5023e-02,  8.4799e-01],\n",
       "         [ 8.8521e-01, -8.1424e-02,  7.9822e-01],\n",
       "         [-3.1439e-01,  1.9095e-02,  9.9659e-01],\n",
       "         [ 3.1439e-01, -1.9095e-02,  9.9623e-01],\n",
       "         [-3.8419e-01,  1.1051e+00,  9.8727e-01],\n",
       "         [ 1.9853e-01,  1.0652e+00,  9.8431e-01],\n",
       "         [-1.1254e-01,  2.1694e+00,  9.6086e-01],\n",
       "         [ 3.7986e-01,  2.0749e+00,  9.5513e-01]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a826bf92fe8f257"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
